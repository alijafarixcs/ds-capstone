{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     c:\\Users\\alire\\Downloads\\neuefische\\ds-\n",
      "[nltk_data]     capstone\\.venv\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     c:\\Users\\alire\\Downloads\\neuefische\\ds-\n",
      "[nltk_data]     capstone\\.venv\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     c:\\Users\\alire\\Downloads\\neuefische\\ds-\n",
      "[nltk_data]     capstone\\.venv\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    "import sys\n",
    "sys.path.append('./lib')\n",
    "from lib.cleaning import *\n",
    "from lib.data_prepration import *\n",
    "from lib.paralellism import *\n",
    "from lib.mydoc2vec import *\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "#!pip install scipy==1.12\n",
    "SEED = 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip install pandarallel\n",
    "!pip install nltk \n",
    "!python.exe -m pip install --upgrade pip\n",
    "!pip install gensim\n",
    "!pip install scipy==1.12 --upgrade\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359775"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keep_cols=['title', 'price', 'helpfulness', 'score', 'time',\n",
    "       'summary', 'text', 'description', 'authors', 'publisher',\n",
    "       'publisheddate', 'categories', 'ratingscount']\n",
    "file_path = '../data/book_review.csv'\n",
    "data_prep = DataPreparation(file_path)\n",
    "data_prep.clean_and_preprocess(True)\n",
    "data_prep.Normalize()\n",
    "data_prep.data=data_prep.data[keep_cols]\n",
    "\n",
    "#data_prep.data=data_prep.data.sample(frac=0.3,random_state=SEED)\n",
    "data_prep.data.categories.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[Fiction]</th>\n",
       "      <td>815445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Juvenile Fiction]</th>\n",
       "      <td>205925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[]</th>\n",
       "      <td>115970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Biography &amp; Autobiography]</th>\n",
       "      <td>104284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Religion]</th>\n",
       "      <td>94700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Bayous]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Bethlehem (Pa.)]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Computer-aided design]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Westchester County (N.Y.)]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Concepts]</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5416 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count\n",
       "categories                         \n",
       "[Fiction]                    815445\n",
       "[Juvenile Fiction]           205925\n",
       "[]                           115970\n",
       "[Biography & Autobiography]  104284\n",
       "[Religion]                    94700\n",
       "...                             ...\n",
       "[Bayous]                          1\n",
       "[Bethlehem (Pa.)]                 1\n",
       "[Computer-aided design]           1\n",
       "[Westchester County (N.Y.)]       1\n",
       "[Concepts]                        1\n",
       "\n",
       "[5416 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep.data.categories=data_prep.data.categories.str.lower().replace(']','').replace('[','')\n",
    "data_prep.data.categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categories\n",
       "[Fiction]                             244248\n",
       "[Juvenile Fiction]                     61813\n",
       "[]                                     34722\n",
       "[Biography & Autobiography]            31277\n",
       "[Religion]                             28347\n",
       "                                       ...  \n",
       "[Devices (Heraldry)]                       1\n",
       "[Adult child sexual abuse victims]         1\n",
       "[Learning disabled youth]                  1\n",
       "[Water quality]                            1\n",
       "[Fractures]                                1\n",
       "Name: count, Length: 3865, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_not_fic=data_prep.data[data_prep.data.categories!=\"[Fiction]\"].sample(frac=0.3)\n",
    "d_fic=data_prep.data[data_prep.data.categories==\"[Fiction]\"].sample(frac=0.12)\n",
    "d_not_fic.categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "keep_cols=['title', 'price', 'helpfulness', 'score', 'time',\n",
    "       'summary', 'text', 'description', 'authors', 'publisher',\n",
    "       'publisheddate', 'categories', 'ratingscount']\n",
    "file_path = '../data/one_half.csv'\n",
    "data_prep = DataPreparation(file_path)\n",
    "data_prep.read_large_csv()\n",
    "random.seed(SEED)\n",
    "\n",
    "data_prep.data=data_prep.data[keep_cols]\n",
    "data_prep.data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_prep.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_prep.data))\n",
    "print(data_prep.data.info())\n",
    "print(data_prep.data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.data.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.generate_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_prep.data.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_func = lambda x: ', '.join(map(str, x))\n",
    "data_prep.data['all']=data_prep.data['title'] + data_prep.data['description'] + data_prep.data['authors'].apply(join_func)+data_prep.data['categories'].apply(join_func)\n",
    "data_prep.data['all']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_doc2vec = Doc2VecRecommender()\n",
    "testdata=_doc2vec.train(data_prep.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_doc2vec.model.save(\"./models/doc2vec_model_hole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_doc2vec_load = Doc2VecRecommender(data_prep.data)\n",
    "_doc2vec_load.load_model('./models/doc2vec_model_hole')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search='after ice age a lion king is back'\n",
    "_doc2vec_load.recommend_by_text(search) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.data=data_prep.data.reset_index()\n",
    "data_prep.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.data.to_csv('../data/cleared_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "def preprocess(sentence,lemmatizer,stop_words_temp=stop_words):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(sentence,language='english')\n",
    "    tokens=[word for word in tokens if word not in stop_words_temp]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "documents = [TaggedDocument(preprocess(doc,lemmatizer), [i]) for i, doc in enumerate(data_prep.data['all'])]\n",
    "def filter_strings_by_length(lst):\n",
    "    return [item for item in lst if len(item) > 2]\n",
    "dts=[','.join(filter_strings_by_length(d.words)) for d in documents]\n",
    "data_prep.data['all_clear']=dts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.data['all_clear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.data.to_csv('../data/cleared_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
