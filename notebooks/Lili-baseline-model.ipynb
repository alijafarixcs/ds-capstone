{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASELINE from ONO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: WordCloud in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from WordCloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from WordCloud) (10.3.0)\n",
      "Requirement already satisfied: matplotlib in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from WordCloud) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->WordCloud) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->WordCloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->WordCloud) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->WordCloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->WordCloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->WordCloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->WordCloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->WordCloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from missingno) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from missingno) (3.7.1)\n",
      "Requirement already satisfied: scipy in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from missingno) (1.14.0)\n",
      "Requirement already satisfied: seaborn in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from missingno) (0.11.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from matplotlib->missingno) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from seaborn->missingno) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from pandas>=0.23->seaborn->missingno) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from pandas>=0.23->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import missingno as msno\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV file using full path\n",
    "book_features = pd.read_csv('/Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/notebooks/data/books_data.csv', low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load data from CSV file\n",
    "ratings = pd.read_csv('/Users/liliyachvileva/Desktop/neuefische/ds-capstone/groupwork/ds-capstone/notebooks/data/Books_rating.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##Checking missing values##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "msno.matrix(book_features)\n",
    "plt.show()\n",
    "\n",
    "msno.matrix(ratings)\n",
    "plt.show()\n",
    "\n",
    "# Calculate missing values\n",
    "print(book_features.isnull().sum())\n",
    "print(ratings.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Cleaning##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Handling missing data and duplicates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in books dataframe\n",
    "book_features = book_features.dropna(subset=['Title', 'description', 'authors'])\n",
    "\n",
    "# Handle missing values in ratings dataframe\n",
    "ratings = ratings.dropna(subset=['Title', 'review/score'])\n",
    "\n",
    "# Remove duplicates if any\n",
    "book_features = book_features.drop_duplicates(subset=['Title'])\n",
    "ratings = ratings.drop_duplicates(subset=['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for data types and converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(book_features.dtypes)\n",
    "print(ratings.dtypes)\n",
    "\n",
    "# Convert data types if necessary\n",
    "book_features['publishedDate'] = pd.to_datetime(book_features['publishedDate'], errors='coerce')\n",
    "ratings['review/time'] = pd.to_datetime(ratings['review/time'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of published dates\n",
    "plt.figure(figsize=(10,6))\n",
    "book_features['publishedDate'].dt.year.value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of Published Dates')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top categories\n",
    "top_categories = book_features['categories'].value_counts().head(10)\n",
    "plt.figure(figsize=(10,6))\n",
    "top_categories.plot(kind='bar')\n",
    "plt.title('Top 10 Book Categories')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rating count distribution\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(book_features['ratingsCount'], bins=10)\n",
    "plt.title('Distribution of Ratings Count')\n",
    "plt.xlabel('Ratings Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authors Analysis\n",
    "top_authors = book_features['authors'].value_counts().head(10)\n",
    "plt.figure(figsize=(10,6))\n",
    "top_authors.plot(kind='bar')\n",
    "plt.title('Top 10 Authors')\n",
    "plt.xlabel('Author')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Word count of description\n",
    "text = ' '.join(book_features['description'].dropna())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Book Descriptions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of review scores\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(ratings['review/score'], bins=10)\n",
    "plt.title('Distribution of Review Scores')\n",
    "plt.xlabel('Review Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of review/helpfulness\n",
    "ratings['helpfulness_numerator'] = ratings['review/helpfulness'].apply(lambda x: int(x.split('/')[0]))\n",
    "ratings['helpfulness_denominator'] = ratings['review/helpfulness'].apply(lambda x: int(x.split('/')[1]))\n",
    "ratings['helpfulness_ratio'] = ratings['helpfulness_numerator'] / ratings['helpfulness_denominator']\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(ratings['helpfulness_ratio'].dropna(), bins=10)\n",
    "plt.title('Distribution of Review Helpfulness Ratio')\n",
    "plt.xlabel('Helpfulness Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top reviewers:\n",
    "top_reviewers = ratings['profileName'].value_counts().head(10)\n",
    "plt.figure(figsize=(10,6))\n",
    "top_reviewers.plot(kind='bar')\n",
    "plt.title('Top 10 Reviewers')\n",
    "plt.xlabel('Reviewer')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking for correlation between price and review score:\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=ratings, x='Price', y='review/score')\n",
    "plt.title('Price vs Review Score')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Review Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Features Engineering##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Rating Count and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rating count for each book\n",
    "rating_counts = ratings.groupby('Title').size().reset_index(name='rating_count')\n",
    "\n",
    "# Calculate the average rating for each book\n",
    "average_ratings = ratings.groupby('Title')['review/score'].mean().reset_index(name='average_rating')\n",
    "\n",
    "# Merge these features into the books dataframe\n",
    "book_features = book_features.merge(rating_counts, on='Title', how='left')\n",
    "book_features = book_features.merge(average_ratings, on='Title', how='left')\n",
    "\n",
    "# Fill NaN values with 0 for rating_count and with the average rating for average_rating\n",
    "book_features['ratingsCount'] = book_features['ratingsCount'].fillna(0)\n",
    "book_features['average_rating'] = book_features['average_rating'].fillna(book_features['average_rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_features[['Title', 'rating_count', 'average_rating']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Summary statistics for the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_features[['rating_count', 'average_rating']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the distribution of the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(book_features['rating_count'], bins=10)\n",
    "plt.title('Distribution of Rating Counts')\n",
    "plt.xlabel('Rating Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(book_features['average_rating'], bins=10)\n",
    "plt.title('Distribution of Average Ratings')\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine relevant text features for vectorization\n",
    "book_features['description'] = book_features['description'].fillna('').str.strip().str.lower()\n",
    "book_features['Title'] = book_features['Title'].fillna('')\n",
    "book_features['authors'] = book_features['authors'].fillna('')\n",
    "book_features['categories'] = book_features['categories'].fillna('')\n",
    "book_features['combined_text'] = book_features['Title'] + ' ' + book_features['description'] + ' ' + book_features['authors'] + ' ' + book_features['categories']\n",
    "\n",
    "\n",
    "# Verify the combined text column\n",
    "print(book_features[['Title', 'combined_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reduce book_data by 50%\n",
    "book_data_reduced = book_features.sample(frac=0.98, random_state=42)\n",
    "\n",
    "# Reduce book_rating by 50%\n",
    "book_rating_reduced = ratings.sample(frac=0.98, random_state=42)\n",
    "\n",
    "# Check the size of the reduced data\n",
    "print(f'Reduced book_data size: {book_data_reduced.shape}')\n",
    "print(f'Reduced book_rating size: {book_rating_reduced.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Transform documents into TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(book_data_reduced['combined_text'])\n",
    "\n",
    "# Use Nearest Neighbors to find similarities\n",
    "nn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "nn.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NearestNeighbors(algorithm='brute', metric='cosine')\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new mapping from book titles to their indices for the reduced dataset\n",
    "indices_reduced = pd.Series(book_data_reduced.index, index=book_data_reduced['Title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_nn(title, n_recommendations=10):\n",
    "    # Get the index of the book that matches the title\n",
    "    idx = indices_reduced[title]\n",
    "\n",
    "    # Get the TF-IDF vector for the book\n",
    "    book_vec = tfidf_matrix[idx]\n",
    "\n",
    "    # Find the nearest neighbors\n",
    "    distances, indices_nn = nn.kneighbors(book_vec, n_neighbors=n_recommendations+1)\n",
    "\n",
    "    # Get the indices of the most similar books\n",
    "    book_indices = indices_nn[0][1:]\n",
    "\n",
    "    # Return the top most similar books\n",
    "    return book_data_reduced[['Title', 'authors', 'categories', 'average_rating', 'ratingsCount']].iloc[book_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage\n",
    "example_title = book_data_reduced['Title'].iloc[1]\n",
    "recommendations = get_recommendations_nn(example_title)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_title = book_data_reduced['Title'].iloc[5]\n",
    "example_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_recommendations_nn(title, true_similar_titles):\n",
    "    # Get the recommendations\n",
    "    recommended_books = get_recommendations_nn(title)\n",
    "    \n",
    "    # Extract the titles of the recommended books\n",
    "    recommended_titles = recommended_books['Title'].tolist()\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    y_true = [1 if title in true_similar_titles else 0 for title in recommended_titles]\n",
    "    y_pred = [1] * len(recommended_titles)  # All recommended books are considered as predicted positive\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ground truth similar titles\n",
    "true_similar_titles = ['Book1', 'Book2', 'Book3', 'Book4', 'Book5', 'Book6', 'Book7', 'Book8', 'Book9', 'Book10']\n",
    "\n",
    "# Example usage\n",
    "precision, recall, f1 = evaluate_recommendations_nn(example_title, true_similar_titles)\n",
    "print(f'Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LILI BASELINE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
